// Audio Intelligence Service - Complete voice interaction system
import { enhancedPersianTTS } from './enhanced-persian-tts';
import { enhancedPersianSpeechRecognition } from './enhanced-persian-speech-recognition';

export interface VoiceCommand {
    text: string;
    type: 'report' | 'general' | 'unknown';
    employeeName?: string;
    confidence: number;
}

export interface AIResponse {
    text: string;
    type: 'success' | 'error' | 'info';
    data?: any;
}

export class AudioIntelligenceService {
    private isProcessing = false;
    private currentSession: string | null = null;

    constructor() {
        console.log('ğŸ¯ Audio Intelligence Service initialized');
    }

    // Helper method to find authentication token
    private findAuthToken(): string | null {
        // Try different methods to get authentication token
        let token = null;

        // Method 1: Check cookies with different possible names
        const cookies = document.cookie.split('; ');
        const possibleTokenNames = ['auth-token', 'token', 'authToken', 'jwt', 'access_token'];

        for (const tokenName of possibleTokenNames) {
            const cookieValue = cookies.find(row => row.startsWith(`${tokenName}=`))?.split('=')[1];
            if (cookieValue) {
                token = cookieValue;
                console.log(`âœ… Found token in cookie: ${tokenName}`);
                break;
            }
        }

        // Method 2: Check localStorage
        if (!token) {
            for (const tokenName of possibleTokenNames) {
                const localStorageValue = localStorage.getItem(tokenName);
                if (localStorageValue) {
                    token = localStorageValue;
                    console.log(`âœ… Found token in localStorage: ${tokenName}`);
                    break;
                }
            }
        }

        // Method 3: Check sessionStorage
        if (!token) {
            for (const tokenName of possibleTokenNames) {
                const sessionStorageValue = sessionStorage.getItem(tokenName);
                if (sessionStorageValue) {
                    token = sessionStorageValue;
                    console.log(`âœ… Found token in sessionStorage: ${tokenName}`);
                    break;
                }
            }
        }

        console.log('ğŸ” Available cookies:', document.cookie);
        console.log('ğŸ” Token found:', token ? 'Yes' : 'No');

        return token;
    }

    // Main method to handle complete voice interaction
    async handleVoiceInteraction(): Promise<{
        transcript: string;
        response: AIResponse;
        success: boolean;
    }> {
        if (this.isProcessing) {
            throw new Error('Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Øª');
        }

        this.isProcessing = true;
        this.currentSession = Date.now().toString();

        try {
            console.log('ğŸ¤ Ø´Ø±ÙˆØ¹ ØªØ¹Ø§Ù…Ù„ ØµÙˆØªÛŒ...');

            // Step 1: Listen to user voice
            const transcript = await this.listenToUser();
            console.log('ğŸ“ Ù…ØªÙ† Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡:', transcript);

            // Step 2: Analyze the command
            const command = this.analyzeVoiceCommand(transcript);
            console.log('ğŸ” Ø¯Ø³ØªÙˆØ± ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡:', command);

            // Step 3: Process the command
            const response = await this.processCommand(command);
            console.log('ğŸ’¬ Ù¾Ø§Ø³Ø® ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:', response.text.substring(0, 100) + '...');

            // Step 4: Speak the response
            await this.speakResponse(response.text);

            return {
                transcript,
                response,
                success: true
            };

        } catch (error) {
            console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¹Ø§Ù…Ù„ ØµÙˆØªÛŒ:', error);

            const errorMessage = error instanceof Error ? error.message : 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ';
            const errorResponse: AIResponse = {
                text: `Ù…ØªØ£Ø³ÙÙ…ØŒ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯: ${errorMessage}`,
                type: 'error'
            };

            // Try to speak the error message
            try {
                await this.speakResponse(errorResponse.text);
            } catch (ttsError) {
                console.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾ÛŒØ§Ù… Ø®Ø·Ø§:', ttsError);
            }

            return {
                transcript: '',
                response: errorResponse,
                success: false
            };

        } finally {
            this.isProcessing = false;
            this.currentSession = null;
        }
    }

    // Listen to user voice input
    private async listenToUser(): Promise<string> {
        try {
            // Test microphone first
            const microphoneOk = await enhancedPersianSpeechRecognition.testMicrophone();
            if (!microphoneOk) {
                console.warn('Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆØ±ÙˆØ¯ÛŒ Ø¯Ø³ØªÛŒ');
                return await enhancedPersianSpeechRecognition.getManualInput();
            }

            // Start listening
            return await enhancedPersianSpeechRecognition.startListening();
        } catch (error) {
            console.error('Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±:', error);

            // Fallback to manual input
            console.log('Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆØ±ÙˆØ¯ÛŒ Ø¯Ø³ØªÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† fallback');
            return await enhancedPersianSpeechRecognition.getManualInput();
        }
    }

    // Analyze voice command to determine type and extract information
    private analyzeVoiceCommand(text: string): VoiceCommand {
        const cleanText = text.toLowerCase().trim();

        // Check for report commands
        const reportKeywords = ['Ú¯Ø²Ø§Ø±Ø´', 'report', 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø±', 'Ú©Ø§Ø±Ú©Ø±Ø¯'];
        const hasReportKeyword = reportKeywords.some(keyword =>
            cleanText.includes(keyword.toLowerCase())
        );

        if (hasReportKeyword) {
            // Extract employee name
            const employeeName = this.extractEmployeeName(text);

            return {
                text,
                type: 'report',
                employeeName,
                confidence: employeeName ? 0.9 : 0.6
            };
        }

        // Check for general questions
        const questionKeywords = ['Ú†ÛŒ', 'Ú†Ù‡', 'Ú©ÛŒ', 'Ú©Ø¬Ø§', 'Ú†Ø±Ø§', 'Ú†Ú¯ÙˆÙ†Ù‡', 'Ø¢ÛŒØ§', 'ØŸ'];
        const hasQuestionKeyword = questionKeywords.some(keyword =>
            cleanText.includes(keyword)
        );

        if (hasQuestionKeyword) {
            return {
                text,
                type: 'general',
                confidence: 0.8
            };
        }

        // Unknown command
        return {
            text,
            type: 'unknown',
            confidence: 0.3
        };
    }

    // Extract employee name from voice command
    private extractEmployeeName(text: string): string | undefined {
        const patterns = [
            /Ú¯Ø²Ø§Ø±Ø´\s*Ú©Ø§Ø±\s*(.+)/i,
            /Ú¯Ø²Ø§Ø±Ø´\s*(.+)/i,
            /report\s*(.+)/i,
            /Ú©Ø§Ø±Ú©Ø±Ø¯\s*(.+)/i
        ];

        for (const pattern of patterns) {
            const match = text.match(pattern);
            if (match && match[1]) {
                return match[1].trim();
            }
        }

        return undefined;
    }

    // Process the analyzed command
    private async processCommand(command: VoiceCommand): Promise<AIResponse> {
        switch (command.type) {
            case 'report':
                return await this.processReportCommand(command);

            case 'general':
                return await this.processGeneralCommand(command);

            default:
                return {
                    text: 'Ù…ØªØ£Ø³ÙÙ…ØŒ Ø¯Ø³ØªÙˆØ± Ø´Ù…Ø§ Ø±Ø§ Ù…ØªÙˆØ¬Ù‡ Ù†Ø´Ø¯Ù…. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…Ø¬Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.',
                    type: 'info'
                };
        }
    }

    // Process report-related commands
    private async processReportCommand(command: VoiceCommand): Promise<AIResponse> {
        if (!command.employeeName) {
            return {
                text: 'Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ù‡Ù…Ú©Ø§Ø± Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯. Ù…Ø«Ø§Ù„: "Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø± Ø§Ø­Ù…Ø¯"',
                type: 'info'
            };
        }

        try {
            // Check authentication first
            console.log('ğŸ” Checking authentication...');
            const authCheck = await fetch('/api/auth/me', {
                method: 'GET',
                credentials: 'include',
            });

            console.log('ğŸ” Auth check response:', authCheck.status, authCheck.ok);

            if (!authCheck.ok) {
                return {
                    text: 'Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´Ø§ØªØŒ Ù„Ø·ÙØ§Ù‹ ÙˆØ§Ø±Ø¯ Ø³ÛŒØ³ØªÙ… Ø´ÙˆÛŒØ¯.',
                    type: 'error'
                };
            }

            const authData = await authCheck.json();
            console.log('ğŸ” Auth data:', authData);

            // Call API to get report
            console.log('ğŸ“ Calling voice-analysis API...');
            const response = await fetch('/api/voice-analysis/process', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                credentials: 'include', // Include cookies
                body: JSON.stringify({
                    text: command.text,
                    employeeName: command.employeeName
                })
            });

            console.log('ğŸ“ Voice-analysis response:', response.status, response.ok);

            const data = await response.json();
            console.log('ğŸ“ Voice-analysis data:', data);

            if (response.ok && data.success) {
                if (data.data.employee_found) {
                    return {
                        text: `Ú¯Ø²Ø§Ø±Ø´ Ù‡Ù…Ú©Ø§Ø± ${data.data.employee_name}:\n\n${data.data.analysis}`,
                        type: 'success',
                        data: data.data
                    };
                } else {
                    return {
                        text: `Ù‡Ù…Ú©Ø§Ø± "${command.employeeName}" Ø¯Ø± Ø³ÛŒØ³ØªÙ… ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.`,
                        type: 'info'
                    };
                }
            } else {
                console.error('âŒ API Error:', response.status, data);
                return {
                    text: `Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´: ${data.message || 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ'} (Status: ${response.status})`,
                    type: 'error'
                };
            }

        } catch (error) {
            console.error('Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú¯Ø²Ø§Ø±Ø´:', error);
            return {
                text: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.',
                type: 'error'
            };
        }
    }

    // Process general questions
    private async processGeneralCommand(command: VoiceCommand): Promise<AIResponse> {
        try {
            const encodedText = encodeURIComponent(command.text);
            const response = await fetch(`https://mine-gpt-alpha.vercel.app/proxy?text=${encodedText}`, {
                method: 'GET',
                headers: {
                    'Accept': 'application/json',
                }
            });

            const data = await response.json();
            const aiText = data.answer || data.response || data.text || data;

            if (aiText && typeof aiText === 'string') {
                return {
                    text: aiText,
                    type: 'success'
                };
            } else {
                return {
                    text: 'Ù…ØªØ£Ø³ÙÙ…ØŒ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… Ù¾Ø§Ø³Ø® Ù…Ù†Ø§Ø³Ø¨ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ù….',
                    type: 'info'
                };
            }

        } catch (error) {
            console.error('Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„ Ø¹Ù…ÙˆÙ…ÛŒ:', error);
            return {
                text: 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.',
                type: 'error'
            };
        }
    }

    // Speak the response using enhanced Persian TTS
    private async speakResponse(text: string): Promise<void> {
        try {
            await enhancedPersianTTS.speak(text);
        } catch (error) {
            console.error('Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾Ø§Ø³Ø®:', error);

            // Don't throw error for TTS issues - just log them
            // The main interaction should continue even if TTS fails
            console.warn('TTS failed but continuing with interaction');
        }
    }

    // Stop any ongoing audio processing
    stopAudioProcessing(): void {
        enhancedPersianSpeechRecognition.stopListening();
        enhancedPersianTTS.stopGracefully();
        this.isProcessing = false;
        this.currentSession = null;
        console.log('â¹ï¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØªÛŒ Ù…ØªÙˆÙ‚Ù Ø´Ø¯');
    }

    // Get system status
    getSystemStatus(): {
        isProcessing: boolean;
        speechRecognitionSupported: boolean;
        ttsSupported: boolean;
        currentSession: string | null;
        voiceInfo: any;
    } {
        return {
            isProcessing: this.isProcessing,
            speechRecognitionSupported: enhancedPersianSpeechRecognition.isSupported(),
            ttsSupported: enhancedPersianTTS.isSupported(),
            currentSession: this.currentSession,
            voiceInfo: enhancedPersianTTS.getVoiceInfo()
        };
    }

    // Test the complete system
    async testSystem(): Promise<{
        speechRecognition: boolean;
        textToSpeech: boolean;
        microphone: boolean;
        overall: boolean;
    }> {
        const results = {
            speechRecognition: enhancedPersianSpeechRecognition.isSupported(),
            textToSpeech: enhancedPersianTTS.isSupported(),
            microphone: false,
            overall: false
        };

        try {
            results.microphone = await enhancedPersianSpeechRecognition.testMicrophone();
        } catch (error) {
            console.error('Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†:', error);
        }

        results.overall = results.speechRecognition && results.textToSpeech && results.microphone;

        return results;
    }
}

// Export singleton
export const audioIntelligenceService = new AudioIntelligenceService();